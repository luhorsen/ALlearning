{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45bc4068",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/yf/PyAL/PHEME/PHEME.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 18\u001b[0m\n\u001b[1;32m     11\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)    \u001b[38;5;66;03m#忽略警告\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# X, y = make_classification(n_samples=500, n_features=10, n_informative=5, n_redundant=2,\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#                            n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0,\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#                            hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/home/yf/PyAL/PHEME/PHEME.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[1;32m     22\u001b[0m     data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m     23\u001b[0m features \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/al/lib/python3.9/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/yf/PyAL/PHEME/PHEME.json'"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "import warnings\n",
    "from alipy import ToolBox\n",
    "warnings.filterwarnings(\"ignore\")    #忽略警告\n",
    "\n",
    "# X, y = make_classification(n_samples=500, n_features=10, n_informative=5, n_redundant=2,\n",
    "#                            n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0,\n",
    "#                            hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "\n",
    "\n",
    "with open(\n",
    "    \"/home/yf/PyAL/PHEME/PHEME.json\",\n",
    "    \"r\",\n",
    ") as file:\n",
    "    data = json.load(file)\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for entry in data:\n",
    "    feature = entry[\"feature\"]\n",
    "    label = int(entry[\"label\"])\n",
    "    features.append(feature)\n",
    "    labels.append(label)\n",
    "\n",
    "# 创建数据集\n",
    "dataset = pd.DataFrame(features)\n",
    "dataset[\"label\"] = labels\n",
    "X = dataset.drop(\"label\", axis=1)\n",
    "y = dataset[\"label\"]\n",
    "# 特征正则化处理\n",
    "\n",
    "features_to_normalize = [\n",
    "    \"Length_of_Characters\",\n",
    "    \"Number_of_Words\",\n",
    "    \"User_Registration_Age\",\n",
    "    \"Number_Of_Followers\",\n",
    "    \"Statuses_Count\",\n",
    "    \"Number_Of_Friends\",\n",
    "]\n",
    "scaler = MinMaxScaler()\n",
    "X[features_to_normalize] = scaler.fit_transform(X[features_to_normalize])\n",
    "# scaler = Normalizer()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = np.array(y)\n",
    "# 准备数据集，假设您的特征数据保存在X变量中，目标变量保存在y变量中\n",
    "X = np.array(X)  # 特征数据\n",
    "\n",
    "\n",
    "alibox = ToolBox(X=X, y=y, query_type=\"AllLabels\", saving_path=\"./\")\n",
    "\n",
    "# Split data\n",
    "alibox.split_AL(\n",
    "    test_ratio=0.3, initial_label_rate=0.003, split_count=10, all_class=True\n",
    ")\n",
    "\n",
    "# Use the default Logistic Regression classifier\n",
    "# model = alibox.get_default_model()\n",
    "model = AdaBoostClassifier()\n",
    "\n",
    "# The cost budget is 50 times querying\n",
    "stopping_criterion = alibox.get_stopping_criterion(\"num_of_queries\", 200)\n",
    "\n",
    "# Use pre-defined strategy\n",
    "uncertainStrategy = alibox.get_query_strategy(strategy_name=\"QueryInstanceDensityWeighted\")\n",
    "unc_result = []\n",
    "\n",
    "for round_exp in range(10):\n",
    "    # Get the data split of one fold experiment\n",
    "    train_idx, test_idx, label_ind, unlab_ind = alibox.get_split(round_exp)\n",
    "    # Get intermediate results saver for one fold experiment\n",
    "    saver = alibox.get_stateio(round_exp)\n",
    "\n",
    "    # Set initial performance point\n",
    "    model.fit(X=X[label_ind.index, :], y=y[label_ind.index])\n",
    "    pred = model.predict(X[test_idx, :])\n",
    "    accuracy = alibox.calc_performance_metric(\n",
    "        y_true=y[test_idx], y_pred=pred, performance_metric=\"accuracy_score\"\n",
    "    )\n",
    "    saver.set_initial_point(accuracy)\n",
    "\n",
    "    while not stopping_criterion.is_stop():\n",
    "        # Select a subset of Uind according to the query strategy\n",
    "        # Passing any sklearn models with proba_predict method are ok\n",
    "        select_ind = uncertainStrategy.select(\n",
    "            label_ind, unlab_ind, model=model, batch_size=1\n",
    "        )\n",
    "        # or pass your proba predict result\n",
    "        # prob_pred = model.predict_proba(x[unlab_ind])\n",
    "        # select_ind = uncertainStrategy.select_by_prediction_mat(unlabel_index=unlab_ind, predict=prob_pred, batch_size=1)\n",
    "\n",
    "        label_ind.update(select_ind)\n",
    "        unlab_ind.difference_update(select_ind)\n",
    "\n",
    "        # Update model and calc performance according to the model you are using\n",
    "        model.fit(X=X[label_ind.index, :], y=y[label_ind.index])\n",
    "        pred = model.predict(X[test_idx, :])\n",
    "        accuracy = alibox.calc_performance_metric(\n",
    "            y_true=y[test_idx], y_pred=pred, performance_metric=\"accuracy_score\"\n",
    "        )\n",
    "\n",
    "        # Save intermediate results to file\n",
    "        st = alibox.State(select_index=select_ind, performance=accuracy)\n",
    "        saver.add_state(st)\n",
    "        saver.save()\n",
    "\n",
    "        # Passing the current progress to stopping criterion object\n",
    "        stopping_criterion.update_information(saver)\n",
    "    # Reset the progress in stopping criterion object\n",
    "    stopping_criterion.reset()\n",
    "    unc_result.append(copy.deepcopy(saver))\n",
    "\n",
    "analyser = alibox.get_experiment_analyser(x_axis=\"num_of_queries\")\n",
    "analyser.add_method(method_name=\"QueryInstanceRandom\", method_results=unc_result)\n",
    "\n",
    "print(analyser)\n",
    "analyser.plot_learning_curves(\n",
    "    title=\"Example of alipy\", std_area=False, saving_path=\"./\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e357528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
