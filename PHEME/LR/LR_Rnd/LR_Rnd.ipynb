{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e95c9dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "| round | initially labeled data | number of queries | cost | Performance: |\n",
      "|   0   |    9 (0.29% of all)    |         1         |  0   | 0.512 ± 0.00 |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zsc/miniconda3/envs/al/lib/python3.9/site-packages/alipy/toolbox.py:173: UserWarning: An existed Toolbox file is detected, load the existed one in case of overwriting. (Delete the old file to create a new Toolbox object)\n",
      "  warnings.warn(\"An existed Toolbox file is detected, load the existed one in case of overwriting. \"\n",
      "/home/zsc/miniconda3/envs/al/lib/python3.9/site-packages/alipy/toolbox.py:228: RuntimeWarning: Data has already been split. Return the existed split in case of overwriting.\n",
      "  warnings.warn(\"Data has already been split. Return the existed split in case of overwriting.\",\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/yf/PyAL/PHEME/LR/LR_Rnd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 110\u001b[0m\n\u001b[1;32m    108\u001b[0m st \u001b[38;5;241m=\u001b[39m alibox\u001b[38;5;241m.\u001b[39mState(select_index\u001b[38;5;241m=\u001b[39mselect_ind, performance\u001b[38;5;241m=\u001b[39maccuracy)\n\u001b[1;32m    109\u001b[0m saver\u001b[38;5;241m.\u001b[39madd_state(st)\n\u001b[0;32m--> 110\u001b[0m \u001b[43msaver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;66;03m# Passing the current progress to stopping criterion object\u001b[39;00m\n\u001b[1;32m    113\u001b[0m stopping_criterion\u001b[38;5;241m.\u001b[39mupdate_information(saver)\n",
      "File \u001b[0;32m~/miniconda3/envs/al/lib/python3.9/site-packages/alipy/experiment/state_io.py:161\u001b[0m, in \u001b[0;36mStateIO.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_saving_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 161\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_saving_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_saving_file_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(\u001b[38;5;28mself\u001b[39m, f)\n\u001b[1;32m    163\u001b[0m f\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/yf/PyAL/PHEME/LR/LR_Rnd'"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "from alipy import ToolBox\n",
    "\n",
    "# X, y = make_classification(n_samples=500, n_features=10, n_informative=5, n_redundant=2,\n",
    "#                            n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0,\n",
    "#                            hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)\n",
    "\n",
    "\n",
    "with open(\n",
    "    \"/home/zsc/Yf/ML/ActivateLearning/Rumor/dataset/pheme.json\",\n",
    "    \"r\",\n",
    ") as file:\n",
    "    data = json.load(file)\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "for entry in data:\n",
    "    feature = entry[\"feature\"]\n",
    "    label = int(entry[\"label\"])\n",
    "    features.append(feature)\n",
    "    labels.append(label)\n",
    "\n",
    "# 创建数据集\n",
    "dataset = pd.DataFrame(features)\n",
    "dataset[\"label\"] = labels\n",
    "X = dataset.drop(\"label\", axis=1)\n",
    "y = dataset[\"label\"]\n",
    "# 特征正则化处理\n",
    "\n",
    "features_to_normalize = [\n",
    "    \"Length_of_Characters\",\n",
    "    \"Number_of_Words\",\n",
    "    \"User_Registration_Age\",\n",
    "    \"Number_Of_Followers\",\n",
    "    \"Statuses_Count\",\n",
    "    \"Number_Of_Friends\",\n",
    "]\n",
    "scaler = MinMaxScaler()\n",
    "X[features_to_normalize] = scaler.fit_transform(X[features_to_normalize])\n",
    "# scaler = Normalizer()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "y = np.array(y)\n",
    "# 准备数据集，假设您的特征数据保存在X变量中，目标变量保存在y变量中\n",
    "X = np.array(X)  # 特征数据\n",
    "\n",
    "\n",
    "alibox = ToolBox(X=X, y=y, query_type=\"AllLabels\", saving_path=\"/home/zsc/Yf/ML/ActivateLearning/Rumor/codes/PHEME/LR/LR_Rnd\")\n",
    "\n",
    "# Split data\n",
    "alibox.split_AL(\n",
    "    test_ratio=0.3, initial_label_rate=0.003, split_count=10, all_class=True\n",
    ")\n",
    "\n",
    "# Use the default Logistic Regression classifier\n",
    "# model = alibox.get_default_model()\n",
    "model = alibox.get_default_model()\n",
    "\n",
    "# The cost budget is 50 times querying\n",
    "stopping_criterion = alibox.get_stopping_criterion(\"num_of_queries\", 200)\n",
    "\n",
    "# Use pre-defined strategy\n",
    "uncertainStrategy = alibox.get_query_strategy(strategy_name=\"QueryInstanceRandom\")\n",
    "unc_result = []\n",
    "\n",
    "for round_exp in range(10):\n",
    "    # Get the data split of one fold experiment\n",
    "    train_idx, test_idx, label_ind, unlab_ind = alibox.get_split(round_exp)\n",
    "    # Get intermediate results saver for one fold experiment\n",
    "    saver = alibox.get_stateio(round_exp)\n",
    "\n",
    "    # Set initial performance point\n",
    "    model.fit(X=X[label_ind.index, :], y=y[label_ind.index])\n",
    "    pred = model.predict(X[test_idx, :])\n",
    "    accuracy = alibox.calc_performance_metric(\n",
    "        y_true=y[test_idx], y_pred=pred, performance_metric=\"accuracy_score\"\n",
    "    )\n",
    "    saver.set_initial_point(accuracy)\n",
    "\n",
    "    while not stopping_criterion.is_stop():\n",
    "        # Select a subset of Uind according to the query strategy\n",
    "        # Passing any sklearn models with proba_predict method are ok\n",
    "        select_ind = uncertainStrategy.select(\n",
    "            label_ind, unlab_ind, model=model, batch_size=1\n",
    "        )\n",
    "        # or pass your proba predict result\n",
    "        # prob_pred = model.predict_proba(x[unlab_ind])\n",
    "        # select_ind = uncertainStrategy.select_by_prediction_mat(unlabel_index=unlab_ind, predict=prob_pred, batch_size=1)\n",
    "\n",
    "        label_ind.update(select_ind)\n",
    "        unlab_ind.difference_update(select_ind)\n",
    "\n",
    "        # Update model and calc performance according to the model you are using\n",
    "        model.fit(X=X[label_ind.index, :], y=y[label_ind.index])\n",
    "        pred = model.predict(X[test_idx, :])\n",
    "        accuracy = alibox.calc_performance_metric(\n",
    "            y_true=y[test_idx], y_pred=pred, performance_metric=\"accuracy_score\"\n",
    "        )\n",
    "\n",
    "        # Save intermediate results to file\n",
    "        st = alibox.State(select_index=select_ind, performance=accuracy)\n",
    "        saver.add_state(st)\n",
    "        saver.save()\n",
    "\n",
    "        # Passing the current progress to stopping criterion object\n",
    "        stopping_criterion.update_information(saver)\n",
    "    # Reset the progress in stopping criterion object\n",
    "    stopping_criterion.reset()\n",
    "    unc_result.append(copy.deepcopy(saver))\n",
    "\n",
    "analyser = alibox.get_experiment_analyser(x_axis=\"num_of_queries\")\n",
    "analyser.add_method(method_name=\"QueryInstanceRandom\", method_results=unc_result)\n",
    "\n",
    "print(analyser)\n",
    "analyser.plot_learning_curves(\n",
    "    title=\"Example of alipy\", std_area=False, saving_path=\"/home/zsc/Yf/ML/ActivateLearning/Rumor/codes/PHEME/LR/LR_Rnd\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f00a0b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
